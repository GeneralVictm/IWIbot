{
  "_args": [
    [
      {
        "raw": "watson-speech",
        "scope": null,
        "escapedName": "watson-speech",
        "name": "watson-speech",
        "rawSpec": "",
        "spec": "latest",
        "type": "tag"
      },
      "C:\\Users\\nkreu\\git\\IWIbot\\IWIbotWebServer"
    ]
  ],
  "_from": "watson-speech@latest",
  "_id": "watson-speech@0.33.0",
  "_inCache": true,
  "_location": "/watson-speech",
  "_nodeVersion": "7.9.0",
  "_npmOperationalInternal": {
    "host": "packages-18-east.internal.npmjs.com",
    "tmp": "tmp/watson-speech-0.33.0.tgz_1493071259350_0.18882313813082874"
  },
  "_npmUser": {
    "name": "nfriedly",
    "email": "nathan@nfriedly.com"
  },
  "_npmVersion": "4.2.0",
  "_phantomChildren": {},
  "_requested": {
    "raw": "watson-speech",
    "scope": null,
    "escapedName": "watson-speech",
    "name": "watson-speech",
    "rawSpec": "",
    "spec": "latest",
    "type": "tag"
  },
  "_requiredBy": [
    "#USER",
    "/"
  ],
  "_resolved": "https://registry.npmjs.org/watson-speech/-/watson-speech-0.33.0.tgz",
  "_shasum": "2dee6fd0c9b51701cfb0b3f2d3d5315cc5a0e678",
  "_shrinkwrap": null,
  "_spec": "watson-speech",
  "_where": "C:\\Users\\nkreu\\git\\IWIbot\\IWIbotWebServer",
  "author": {
    "name": "Nathan Friedly",
    "email": "http://nfriedly.com"
  },
  "bugs": {
    "url": "https://github.com/watson-developer-cloud/speech-javascript-sdk/issues"
  },
  "dependencies": {
    "clone": "^2.1.0",
    "defaults": "^1.0.3",
    "get-user-media-promise": "^1.1.0",
    "lodash.pullallwith": "^4.7.0",
    "microphone-stream": "^3.0.5",
    "nodeify-fetch": "^0.1.2",
    "object.assign": "^4.0.4",
    "object.pick": "^1.2.0",
    "readable-blob-stream": "^1.1.0",
    "websocket": "^1.0.24",
    "whatwg-fetch": "^2.0.1"
  },
  "description": "IBM Watson Speech to Text and Text to Speech SDK for web browsers.",
  "devDependencies": {
    "browserify": "^14.0.0",
    "concat-stream": "^1.6.0",
    "envify": "^4.0.0",
    "envify-loader": "^0.1.0",
    "eslint": "^3.13.1",
    "eslint-config-google": "^0.7.1",
    "eslint-config-prettier": "^1.0.3",
    "eslint-plugin-prettier": "^2.0.0",
    "expect.js": "^0.3.1",
    "jquery": "^3.1.1",
    "jsdoc": "^3.4.3",
    "karma": "^1.3.0",
    "karma-browserify": "^5.1.0",
    "karma-chrome-launcher": "^2.0.0",
    "karma-eslint": "^2.2.0",
    "karma-express-http-server": "0.0.1",
    "karma-firefox-launcher": "^1.0.0",
    "karma-mocha": "^1.3.0",
    "memory-fs": "^0.4.1",
    "mocha": "^3.2.0",
    "prettier": "^0.18.0",
    "serve-static": "^1.11.1",
    "sinon": "^1.17.7",
    "uglify-js": "^2.7.5",
    "watchify": "^3.8.0",
    "watson-developer-cloud": "^2.14.5",
    "webpack": "^2.2.1"
  },
  "directories": {},
  "dist": {
    "shasum": "2dee6fd0c9b51701cfb0b3f2d3d5315cc5a0e678",
    "tarball": "https://registry.npmjs.org/watson-speech/-/watson-speech-0.33.0.tgz"
  },
  "gitHead": "1f9e2ec81f5e61bbc973725dff1f7feb3cb4e142",
  "homepage": "http://watson-speech.mybluemix.net/",
  "license": "Apache-2.0",
  "main": "index.js",
  "maintainers": [
    {
      "name": "germanattanasio",
      "email": "germanattanasio@gmail.com"
    },
    {
      "name": "nfriedly",
      "email": "nathan@nfriedly.com"
    }
  ],
  "name": "watson-speech",
  "optionalDependencies": {},
  "readme": "IBM Watson Speech Services for Web Browsers\n===========================================\n\n[![Build Status](https://travis-ci.org/watson-developer-cloud/speech-javascript-sdk.svg?branch=master)](https://travis-ci.org/watson-developer-cloud/speech-javascript-sdk)\n[![npm-version](https://img.shields.io/npm/v/watson-speech.svg)](https://www.npmjs.com/package/watson-speech)\n\nAllows you to easily add voice recognition and synthesis to any web app with minimal code.\n\n### Built for Browsers\nThis library is primarily intended for use in web browsers. Check out [watson-developer-cloud](https://www.npmjs.com/package/watson-developer-cloud) to use Watson services (speech and others) from Node.js.\n\nHowever, a **server-side component is required to generate auth tokens**. The examples/ folder includes example Node.js and Python servers, and SDKs are available for [Node.js](https://github.com/watson-developer-cloud/node-sdk#authorization), [Java](https://github.com/watson-developer-cloud/java-sdk), [Python](https://github.com/watson-developer-cloud/python-sdk/blob/v0.33.0/examples/authorization_v1.py), and there is also a [REST API](https://www.ibm.com/watson/developercloud/doc/common/getting-started-tokens.html).\n\n\n### Installation - standalone\n\nPre-compiled bundles are available from on GitHub Releases - just download the file and drop it into your website: https://github.com/watson-developer-cloud/speech-javascript-sdk/releases\n\n### Installation - bower\n\n```sh\nbower install --save watson-speech\n```\n\n### Installation - npm with Browserify or Webpack\n\nThis library can be bundled with [browserify](http://browserify.org/) or [Webpack](http://webpack.github.io/)\nand easy included in larger projects:\n\n    npm install --save watson-speech\n\nThis method enables a smaller bundle by only including the desired components, for example:\n\n```js\nvar recognizeMic = require('watson-speech/speech-to-text/recognize-microphone');\n```\n\n\nBreaking change for v0.22.0\n----------------------------\n\nThe format of objects emitted in objectMode has changed from `{alternatives: [...], index: 1}` to `{results: [{alternatives: [...]}], result_index: 1}`.\n\nThere is a new `ResultExtractor` class that restores the old behavior; `recognizeMicrophone()` and `recognizeFile()` both accept a new `extract_results` option to enable it.\n\nThis was done to enable the new `speaker_labels` feature. The format now exactly matches what the Watson Speech to Text service returns and shouldn't change again unless the Watson service changes.\n\n\nAPI & Examples\n--------------\n\nThe basic API is outlined below, see complete API docs at http://watson-developer-cloud.github.io/speech-javascript-sdk/v0.33.0/\n\nSee several basic examples at http://watson-speech.mybluemix.net/ ([source](https://github.com/watson-developer-cloud/speech-javascript-sdk/tree/v0.33.0/examples/))\n\nSee a more advanced example at https://speech-to-text-demo.mybluemix.net/\n\nAll API methods require an auth token that must be [generated server-side](https://github.com/watson-developer-cloud/node-sdk#authorization). \n(See https://github.com/watson-developer-cloud/speech-javascript-sdk/tree/v0.33.0/examples/ for a couple of basic examples in Node.js and Python.)\n\n## [`WatsonSpeech.TextToSpeech`](http://watson-developer-cloud.github.io/speech-javascript-sdk/v0.33.0/module-watson-speech_text-to-speech.html)\n\n### [`.synthesize({text, token})`](http://watson-developer-cloud.github.io/speech-javascript-sdk/v0.33.0/module-watson-speech_text-to-speech_synthesize.html) -> `<audio>`\n\nSpeaks the supplied text through an automatically-created `<audio>` element. \nCurrently limited to text that can fit within a GET URL (this is particularly an issue on [Internet Explorer before Windows 10](http://stackoverflow.com/questions/32267442/url-length-limitation-of-microsoft-edge)\nwhere the max length is around 1000 characters after the token is accounted for.)\n\nOptions: \n* text - the text to speak\n* voice - the desired playback voice's name - see .getVoices(). Note that the voices are language-specific.\n* customization_id - GUID of a custom voice model - omit to use the voice with no customization.\n* autoPlay - set to false to prevent the audio from automatically playing\n\nRelies on browser audio support: should work reliably in Chrome and Firefox on desktop and Android. Edge works with a little help. Safari and all iOS browsers do not seem to work yet.\n\n## [`WatsonSpeech.SpeechToText`](http://watson-developer-cloud.github.io/speech-javascript-sdk/v0.33.0/module-watson-speech_speech-to-text.html)\n\nThe `recognizeMicrophone()` and `recognizeFile()` helper methods are recommended for most use-cases. They set up the streams in the appropriate order and enable common options. These two methods are documented below.\n\nThe core of the library is the [RecognizeStream] that performs the actual transcription, and a collection of other Node.js-style streams that manipulate the data in various ways. For less common use-cases, the core components may be used directly with the helper methods serving as optional templates to follow. The full library is documented at http://watson-developer-cloud.github.io/speech-javascript-sdk/v0.33.0/module-watson-speech_speech-to-text.html\n\n### [`.recognizeMicrophone({token})`](http://watson-developer-cloud.github.io/speech-javascript-sdk/v0.33.0/module-watson-speech_speech-to-text_recognize-microphone.html) -> Stream\n\nOptions: \n* `keepMic`: if true, preserves the MicrophoneStream for subsequent calls, preventing additional permissions requests in Firefox\n* `mediaStream`: Optionally pass in an existing media stream rather than prompting the user for microphone access.\n* Other options passed to [RecognizeStream]\n* Other options passed to [SpeakerStream] if `options.resultsbySpeaker` is set to true\n* Other options passed to [FormatStream] if `options.format` is not set to false\n* Other options passed to [WritableElementStream] if `options.outputElement` is set\n\nRequires the `getUserMedia` API, so limited browser compatibility (see http://caniuse.com/#search=getusermedia) \nAlso note that Chrome requires https (with a few exceptions for localhost and such) - see https://www.chromium.org/Home/chromium-security/prefer-secure-origins-for-powerful-new-features\n\nNo more data will be set after `.stop()` is called on the returned stream, but additional results may be recieved for already-sent data.\n\n\n### [`.recognizeFile({data, token})`](http://watson-developer-cloud.github.io/speech-javascript-sdk/v0.33.0/module-watson-speech_speech-to-text_recognize-file.html) -> Stream\n\nCan recognize and optionally attempt to play a URL, [File](https://developer.mozilla.org/en-US/docs/Web/API/File) or [Blob](https://developer.mozilla.org/en-US/docs/Web/API/Blob)\n(such as from an `<input type=\"file\"/>` or from an ajax request.)\n\nOptions: \n* `file`: a String URL or a `Blob` or `File` instance. Note that [CORS] restrictions apply to URLs.\n* `play`: (optional, default=`false`) Attempt to also play the file locally while uploading it for transcription \n* Other options passed to [RecognizeStream]\n* Other options passed to [TimingStream] if `options.realtime` is true, or unset and `options.play` is true\n* Other options passed to [SpeakerStream] if `options.resultsbySpeaker` is set to true\n* Other options passed to [FormatStream] if `options.format` is not set to false\n* Other options passed to [WritableElementStream] if `options.outputElement` is set\n\n`play`requires that the browser support the format; most browsers support wav and ogg/opus, but not flac.) \nWill emit an `UNSUPPORTED_FORMAT` error on the RecognizeStream if playback fails. This error is special in that it does not stop the streaming of results.\n\nPlayback will automatically stop when `.stop()` is called on the returned stream. \n\nFor Mobile Safari compatibility, a URL must be provided, and `recognizeFile()` must be called in direct response to a user interaction (so the token must be pre-loaded).\n\n\n## Changes\n\nThere have been a few breaking changes in recent releases:\n\n* Removed `SpeechToText.recognizeElement()` due to quality issues. The code is [avaliable in an (unsupported) example](https://github.com/watson-developer-cloud/speech-javascript-sdk/tree/v0.33.0/examples/static/audio-video-deprecated) if you wish to use it with current releases of the SDK.\n* renamed `recognizeBlob` to `recognizeFile` to make the primary usage more apparent\n* Changed `playFile` option of `recognizeBlob()` to just `play`, corrected default\n* Changed format of objects emitted in objectMode to exactly match what service sends. Added `ResultStream` class and `extract_results` option to enable older behavior.\n* Changed `playback-error` event to just `error` when recognizing and playing a file. Check for `error.name == 'UNSUPPORTED_FORMAT'` to identify playback errors. This error is special in that it does not stop the streaming of results.\n* Renamed `recognizeFile()`'s `data` option to `file` because it now may be a URL. Using a URL enables faster playback and mobile Safari support\n\nSee [CHANGELOG.md](CHANGELOG.md) for a complete list of changes.\n\n## todo\n\n* Further solidify API\n* break components into standalone npm modules where it makes sense\n* run integration tests on travis (fall back to offline server for pull requests)\n* add even more tests\n* better cross-browser testing (IE, Safari, mobile browsers - maybe saucelabs?)\n* update node-sdk to use current version of this lib's RecognizeStream (and also provide the FormatStream + anything else that might be handy)\n* move `result` and `results` events to node wrapper (along with the deprecation notice)\n* improve docs\n* consider a wrapper to match https://dvcs.w3.org/hg/speech-api/raw-file/tip/speechapi.html\n* support a \"hard\" stop that prevents any further data events, even for already uploaded audio, ensure timing stream also implements this.\n* look for bug where single-word final results may omit word confidence (possibly due to FormatStream?)\n* fix bug where TimingStream shows words slightly before they're spoken\n\n[RecognizeStream]: http://watson-developer-cloud.github.io/speech-javascript-sdk/v0.33.0/RecognizeStream.html\n[TimingStream]: http://watson-developer-cloud.github.io/speech-javascript-sdk/v0.33.0/TimingStream.html\n[FormatStream]: http://watson-developer-cloud.github.io/speech-javascript-sdk/v0.33.0/FormatStream.html\n[WritableElementStream]: http://watson-developer-cloud.github.io/speech-javascript-sdk/v0.33.0/WritableElementStream.html\n[SpeakerStream]: http://watson-developer-cloud.github.io/speech-javascript-sdk/v0.33.0/SpeakerStream.html\n[CORS]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS\n",
  "readmeFilename": "README.md",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/watson-developer-cloud/speech-javascript-sdk.git"
  },
  "scripts": {
    "autofix": "eslint . --fix",
    "browserify": "browserify index.js --standalone WatsonSpeech --outfile dist/watson-speech.js --transform envify",
    "build": "npm run webpack && npm run minify",
    "doc": "jsdoc -c scripts/jsdoc/config.json --debug",
    "lint": "eslint .",
    "minify": "uglifyjs --compress --mangle --screw-ie8 dist/watson-speech.js --output dist/watson-speech.min.js --preamble \"// IBM Watson Speech JavaScript SDK\n// $npm_package_version\n// Generated at `date`\n// Copyright IBM ($npm_package_license)\n// $npm_package_homepage\"",
    "test": "npm run lint &&npm run test-offline",
    "test-integration": "TEST_MODE=integration karma start --single-run",
    "test-offline": "karma start --single-run",
    "watch-doc": "nodemon --watch ./ --ignore ./doc --ext js,tmpl,json --exec npm run doc",
    "watch-test": "karma start",
    "watchify": "watchify index.js --standalone WatsonSpeech --outfile dist/watson-speech.js --debug --verbose",
    "webpack": "webpack"
  },
  "version": "0.33.0"
}
